%    Template for seminar reports
% Seminar Current Topics in Computer Vision and Machine Learning
% Summer Semester 2015
% Computer Vision Group, Visual Computing Institute, RWTH Aachen

\documentclass[twoside,a4paper,article]{combine}
%\documentclass[11pt,twoside,a4paper]{article}

% =========================================================================
\usepackage[latin1]{inputenc}
\usepackage{a4}
\usepackage{fancyhdr}   
%\usepackage{german}    % Uncomment this iff you're writing the report in German
\usepackage{makeidx}
\usepackage{color}
\usepackage{t1enc}		% 	german letters in the "\hyphenation" - command
\usepackage{latexsym}	% math symbols
\usepackage{amssymb}    % AMS symbol fonts for LaTeX.
\usepackage{amsmath} 
\usepackage{graphicx}
\usepackage{pslatex}
\usepackage{ifthen}

\usepackage[T1]{fontenc}
\usepackage{pslatex}

\usepackage{psfrag}
\usepackage{subfigure}
\usepackage{url}

% =========================================================================

\setlength{\oddsidemargin}{3.6pt}
\setlength{\evensidemargin}{22.6pt}
\setlength{\textwidth}{426.8pt}
\setlength{\textheight}{654.4pt}
\setlength{\headsep}{18pt}
\setlength{\headheight}{15pt}
\setlength{\topmargin}{-41.7pt}
\setlength{\topskip}{10pt}
\setlength{\footskip}{42pt}

\setlength{\parindent}{0pt}

% =========================================================================

\graphicspath{
	{pictures/}
}

%%%
% We want also subsubsections to be enumerated
%%%
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

\makeglossary
%\makeindex

% =========================================================================
\begin{document}

\include{titlepage}

\begin{abstract}
% +++++++++++++++++++++++++
% Insert your Abstract here
% +++++++++++++++++++++++++
\end{abstract}

\tableofcontents
\newpage
% =========================================================================


\section{Introduction}
\cite{Ladd2010} General Possible Quantum Computer. 

\cite{Boixo2016} The supremacy.

\cite{Ronnow2014} Detect quantum speed up\\

Adiabatic quantum annealing is a kind of quantum computation achieved by adiabatic evolution and quantum annealer is a device that can perform adiabatic quantum annealing. The idea of quantum computation was brought up in early 80s \cite{Feynman1982}. It indicated that a simulation of quantum phenomena is not always available on an classical computer, because the amount of resource required grows exponentially along with the size of the physical system. Instead, a quantum phenomena should be simulate by a computer making use of quantum property. The amount of resource required by the simulation is only proportional to the size of the physical system. \\

After this idea, an interesting topic for scientist is that how computation can benefit from storing, transferring and processing information with quantum properties. Quantum computation is expected to do more than just simulation of a quantum phenomena. Some quantum algorithm has been presented and shown to have a significantly speed-up compared to classical ones. The following are some example. Simon's algorithm can reduce the runtime for the task from an exponential time on a classical computer to a polynomial time on a quantum computer. \cite{Simon1994}. Furthermore, this also serve as the stepping-stone to Shor's Algorithm. Shor's Algorithm for factoring is one of the most well-know quantum algorithm. The time it takes to factor an n-digit number grows as a polynomial in n on a quantum computer. The time for the same task grows exponentially with n on a classical computer \cite{Shor1995}. The toughness of factoring problem is the basis of many cryptography techniques and information is usually encrypted and protected by a large semi prime number. Classical cryptography seems to break down and  quantum cryptography is under research as a response to this. The last one is Grover's search algorithm. To search an item in an unstructured list of size N costs a classical computer running time in an order of N. Grover's algorithm can solve the same task in the order of $\sqrt{N}$ \cite{Grover1996}. Not like Shor's algorithm, which has an exponential speed-up, Grover's algorithm has only a quadratic improvement. It is still a important algorithm because of its board applications, such as speedup the time required to solve NP-complete problems \cite{Cerf2000} \cite{Bennett1997}. \\

All algorithm mentioned above are expected to run on an universal quantum computer, which is usually referred to a machine based on quantum gate modal. However, building an quantum gate computer may be a challenging task. The main difficulty comes from the close box requirement \cite{Ladd2010}. The quantum system of a quantum computer should be isolated from its environment while being controlled. The quantum system which computation based on is so fragile that even a little amount of noise can cause harm to the system, known as decoherence. Furthermore, due to the environmental noise, the entropy of the system will keep increasing along with the time. Therefore, there must exist a way to coll the quantum system and maintain its quantum state. How to measure results is another a important issue, because the computational result makes sense to us only when we are able to measure it. Also, the possibility to scale up the system is crucial. A general quantum computing can be realised only when the above requirement are all fulfilled. Gate based computer is still struggling. Another approach to quantum computation is adiabatic quantum computer, which has more robustness than a gate based computer !!cite decoherence in AQC!!. There are debates on whether adiabatic quantum computer can be consider as a general quantum computer. It has shown that the model of adiabatic computation differs from the standard model of quantum computation within a polynomial time \cite{Aharonov2004}\cite{Farhi2000}. Some criticized that this only hold under ideal situation without noise. There are effective model for building a fault-tolerant gate based computer. By contrast, whether fault-tolerant is possible on quantum annealing computer remains unknown !!cite Classical signature of quantum annealing!!
\\

D-Wave System Inc. is a company which focus on building quantum annealing computer and the target problem of it is optimisation problem. Among optimisation problems, many can be cast into a problem of finding the minimum point of the cost function, which is equivalent to the ground state of a system of interacting spins. Finding such state remains still a computational hard problem. It is believed that if one can encode the cost function into the hardware, quantum annealing process can effectively achieve the goal\cite{Johnson2011}. During a quantum annealing process, the system start from a ground state and evolve in time with a problem Hamiltonian. In the end of evolution, the system are expected to be in the ground stated of the problem Hamiltonian, which is the solution to the optimisation problem. This is the reason why quantum annealing computer is sometimes considered specialized only in optimisation instead of universal quantum computer. D-wave System was founded  in 1999 and claimed to release the first commercial system in 2010 with 128 qubits. The latest system is D-Wave 2000Q with 2048 qubits. By emphasising on optimisation, quantum annealing computer has potential in the fields like machine learning, pattern recognition and computer vision. 
\\

Quantum annealer is built based on spin 1/2 system, which is Ising-model. The qubit in this system has two state, which is perfect for solving the 2-SAT problems. Start from an initial Hamiltonian, we slowly turn off this initial Hamiltonian and turn on the problem Hamiltonian. If the system is at its ground state and the whole process is slow enough, the system will also end at ground state with the problem Hamiltonian and we get th e solution of the 2-SAT problem. According to the adiabatic theorem this should work in a pure system, however, in the real case with environment. The system will be coupled with a heat bath. This heat bath may damage the coherent of the system evolution. \\ 

The outline of the report is as follows. In the section 2, the general idea of quantum annealer and the theory behind it will be introduced. Section 3 present the definition and the characteristic of optimisation problem. Section 4 provide the algorithms used for the simulation of a spin-system. In Section 5 and section 6, the simulation results of a ideal system and a system with Temperature effect will be discuss respectively. Section 7 is about some applications on machine learning and computer vision based on quantum annealing.
\\

% In section 3, I will introduce the optimization porblem, which believed to be a potential application of the quantum annealer. In section 4, I first simulate the quantum annealer without the heat bath. In section 5, I then simulate the quantum annealing process with hear bath. In the last section we try to discuss the possibility of using quantum annealing for machine learning.  \\

\newpage

\section{( Theory of ) Quantum Annealer}

!A quantum annealer is a specialised machine that solves optimisation problems by evolving from a know initial configuration to the ground state of a Hamiltonian encoding a given problem.


\cite{Das2008} 
\cite{Matsuda2009}
\cite{Santoro2006}
\cite{Denchev2015} what is the computational value of finite range tunnelling




\subsection{Quantum Annealing and Adiabatic Quantum Computation}
\cite{Boixo2014} A compare of quantum annealing and simulated annealing \\
\cite{QABoixo2016} Multi qubit tunneling \\
\cite{Jin2013} quantum decoherence \\
\cite{Smolin2013} Classical signature of quantum annealing p2 \\

Before going into quantum annealing, it's worth mentioning first the reason using annealing technique in general and the difference between simulated annealing and quantum annealing. First, the reason using annealing technique is because of the properties of the combinatorial optimisation problem. The goal of this kind of problem is to find an optimal solution among a finite set of possible configuration. The set of solution is discrete. A brute-force search for the optimal one is not practical on a classical computer when the problem size is large. To reduce runtime, one approximate method is annealing. If one can encode the problem into a cost function and correspond the minimum value of the cost function to the solution of the optimisation problem, annealing algorithm can help find the lowest point in the landscape constructed by the cost function.  \\

Annealing algorithm is inspired by the annealing in metallurgy and material science. It is a heat treatment that heating a material up to a temperature that recrystallisation can occurs, and cooling it down. Recrystalisation process lower the free energy of the crystals \cite{Schader2012}. It's an ancient technique to improves the properties of material and makes it more workable. \\

Following this process, simulated annealing is a optimisation method for approximating global minimum of a given function. In simulated annealing, the system starts from a high energy state and by lowering the temperature very slowly, the system is expected to end up in the lowest energy state or at least a close approximation. However, there are two situation which may turn simulated annealing into a inefficient algorithm. First, if the landscape is too rugged and the energy barrier around local minima is too high, the system may get stuck in one of the local minima which is apparently not the optimal solution. These deep barrier may trap the system for a very long time during the evolving. The second problem is the complexity. The number of possible solutions grows exponentially with the problem size, because $n$ Ising spins have $2^n$ configurations. Simulated annealing can only go through one configuration at a time. !Unless there is a gradient can guide the system toward the global minimum from any point of the configuration space, simulated algorithm can do no better than a random search one. \\



On the other hand, quantum annealing may become more efficient and perform better than simulated annealing when facing these two situations, because the phenomenon of quantum tunnelling help explore more search space. More precisely, quantum mechanics allows the system to tunnel through very high barriers in a classically inaccessible path once barriers are narrow enough. !Furthermore, if the Hamiltonian of a given problem is applied properly to the system, the quantum mechanical wave function can delocalise over the whole search space, that is, it has the ability to see the entire landscape during annealing. In contrast, simulated annealing can only search the configuration space randomly and escape from local minimum by the aid of thermal fluctuations. Therefore, quantum annealing is superior to simulated annealing algorithm in these two aspect. However, empirically quantum annealing does not always improve the search process and it has its own limitation. Some counter cases has been observed for k-SAT problems \cite{Battaglia2005}. In brief, although for both algorithms the system may stop evolving at a local minimum state instead of the global minimum, if the barrier constraining the local minimum is narrow enough, the quantum tunnelling can give the system have a chance to tunnel through the barrier and keep evolving toward the true minimum. An illustration is shown in Fig.\ref{diff_qa_ca}. \\ 

\begin{figure}[h]
	\centering
	\includegraphics[height=150pt]{qaca.png}
	\caption{The difference between QA and CA. Image from \cite{Das2008}. }
	\label{diff_qa_ca}
\end{figure}



 

%The idea of annealing in general is to find the lowest-energy state, which sometime cast into a problem that try to find the lowest value of a cost function. When performing classic annealing, the system start from a random state in a high temperature. Then the temperature decrease, simulated algorithm choose the new state by some criteria. The system evolve by reducing the energy, and the result is usually end up in a local minima instead of global minima. !!The choose criteria\\

The main dynamics in quantum annealing process is quantum fluctuation. To achieve this, the system is first prepared in the ground state of the initial Hamiltonian, which is a product states of all spin states. Next, to bring in quantum fluctuation, a strong transverse field is applied to they system. During the annealing, the transverse field is slowly turned off while the problem Hamiltonian is slowly turned on. If this procedure progress slowly enough, the system will stay still in the ground state. At the end of the annealing process, the transverse field is complete off and the system should have evolved to the ground state of the problem Hamiltonian that encoded the given optimisation problem. The Hamiltonian used here is from classical Ising model and will be introduced in the next paragraph. How to encode an optimisation problem into a Ising model Hamiltonian will be presented in detail in Section \ref{The Mapping of Hamiltonian}. \\

%\begin{equation}
%H_{problem}=\sum_{i,j}^N \{J^x \sigma^x_i \sigma^x_j+J^y \sigma^y_i \sigma^y_j+J^z \sigma^z_i \sigma^z_j \}+ \sum_{i}^N \{h^x \sigma^x_i+h^y \sigma^y_i+h^z \sigma^z_i\}
%\end{equation}

%\begin{equation}
%H_{Ising}=\sum_{i,j}^N \{J^z \sigma^z_i \sigma^z_j \}+ \sum_{i}^N \{h^z \sigma^z_i\}
%\end{equation}

\begin{equation}
H_{Ising}=\sum_{i,j}^N \{J_{ij} \sigma_i \sigma_j \}+ \sum_{i}^N \{h_i \sigma_i\}.
\end{equation}
!The Hamiltonian of classical Ising model with N spins can be written as above. This model is broadly used in statistical physics to show a phase transition. The formula describe a set of lattice sites with discrete variables that represent the atomic spins with either up or down state. The model allows interaction between neighbours according to factor $J_{ij}$. If $J_{ij}<0$, the interaction is called ferromagnetic and the neighbour spins have higher probability to align parallel. In contrast, if $J_{ij}>0$, it is antiferromagnetic and the neighbour spins favour opposite states. Similarly, An external field $h_i$ interacts with each spin. The spin tends to have negative direction when $h_i>0$, and positive direction when $h_i<0$. Obviously, finding the configuration of the ground state under a given parameter set is the main and difficult task after one maps a optimisation problem into the Hamiltonian. \\

Based on classical Ising model, the Hamiltonian used by quantum annealing process can be written as follow

\begin{equation}
\begin{split}
&H(t)=(1-\frac{t}{T} )H_{init}+(\frac{t}{T})H_{problem} \\
&H_{init}= \sum_{i=1}^{N}h_i^x \sigma_i^x\\
&H_{problem}= \sum_{i,j}^N \{J_{ij}^z \sigma^z_i \sigma^z_j \}+ \sum_{i}^N \{h_i^z \sigma^z_i\},\\
\end{split}
\end{equation} 

where t is the current timestep, T is toatal annealing time,\\
Hinit
Hproblem



%Quantum annealing does not evolve by reducing temperature. The system is affect by two Hamiltonian, one is $H_i$, which is our starting Hamiltonian, and the requirement of this Hamiltonian is that the ground state of this is easy to prepared. On the other hand, $H_p$ is the problem Hamiltonian. We map the problem in to $H_p$. The idea is that, if we start from the ground state of $H_i$, and then the $H_i$ is turned off and the $H_p$ is turned on sufficiently slow. The system will end up in the ground state of $H_p$, which is the solution we want to find.\\

In the ideal case, the classical annealing has some random factor, and the QA does not. Therefore a idea QA will always find the solution, or never, which leads to a bimodal distribution. Classical annealing starts from a random state, on the other hand, may have a uni-modal result. this is consider as a criteria for quantumness. !!Quantum annealing with more than one hundred qubits!! they declare to have this quantum characteristic. but the !!Classical signature of quantum annealing!! claimed that by picking same random state, the CA can also show a bimodal result. \\
\\

!!cite Quantum Computation by Adiabatic Evolution Farhi 2000!!

The adiabatic quantum annealing algorithm is implement as follow:\\
\\
1. An ground state of $H_i$ is construct.
\begin{equation*}
	H_i=\sum_{i=1}^{N}h_i^x \sigma_i^x
\end{equation*}   

2. Construct a Hamiltonian from a given problem.
\begin{equation*}
	H_{problem}=\sum_{i,j} \{J^x \sigma^x_i \sigma^x_j+J^y \sigma^y_i \sigma^y_j+J^z \sigma^z_i \sigma^z_j \}+ \sum_{i} \{h^x \sigma^x_i+h^y \sigma^y_i+h^z \sigma^z_i\}
\end{equation*}   

3. Evolve the system according to the time scheme.
\begin{equation*}
	T:linear 
\end{equation*}

4. Compute Schrodinger eqaution according to the above.\\
\\
5. The final state will be in the ground state of the $H_p$, if annealing T is long enough.\\
\\
6. measure the coefficient value of the state. then we have the solution.\\
\\



QA is a technique to find the ground state of a optimisation problem. different from the thermal annealing is that can tunnel through the barrier. 


\subsubsection{Time-Dependent Schrodinger Equation}
\begin{equation*}
i\hbar\frac{\partial \psi}{\partial t}=H\psi
\end{equation*}

\begin{equation*}
H=(1-\lambda)H_{init}+\lambda H_{problem}
\end{equation*}
\begin{equation*}
H_{init}=\sum_{i} h^x_{init} \sigma^x_i
\end{equation*}


\subsection{Adiabatic Theorem}
Once the annealing time is long enough. We should be able to find the ground state.
\subsection{Landau-Zener Theorem}
The probability of finding the ground state is depend on the temperature and the gap.

\subsection{Annealing Time scheme}
From the previous sector, we can noticed that the time scheme for $\lambda$ should be chosen and set. Here we use linear scheme for $\lambda$.


\section{Optimisation Problem}
\subsection{Combinatorial Optimisation}

Combinatorial optimisation problem is one of the most important task people want to solve. If one need to find the best choice among all available options consist of many independent factors, it can be considered as a combinatorial optimisation problem. Some practical examples are like travelling salesman problem, closure problem and assignment problem. Take travelling salesman problem for instance, there are N cities located randomly in an area and the goal is to plan an trip that visit every city once in the shortest travel distance. A straightforward approach is to try out all permutations and find the shortest path. The running time for this brute-force search is $\mathcal{O}(n!)$ , which means it grows as the factorial of the number of cities and the search space easily becomes too large for this approach to be feasible even for a relatively small N ($N \sim 30$) \cite{Santoro2006}. \\

Many combinatorial optimisation problems can be cast into a problem of minimising a given cost function $H(S_1,S_2,S_3,...S_N)$ with respect to N variables $S_1$, $S_2$ to $S_N$ \cite{Das2008}. The aim is to determine a set of values for the variables that yield the minimum value of the cost function. Combinatorial optimisation problem often has the following properties. The optimal solution is searched from a finite set of objects. The set of objects is discrete. Brute-force search is usually not feasible. Besides, even some problems with continuous variables can be reduced to combinatorial problems \cite{Papadimitriou1984}. \\

In the field of computer science, the complexity of a computational task are classified by the running time needed by the fastest algorithm relative to the size of the task. If a given task can be solved in polynomial time by using polynomial bound resource on classical computer, it is considered to be in the class P. Although a P problem does not necessary means an easy problem, a polynomial bond on the evaluation time implies its difficulty won't grow exponentially along with the problem size. Unfortunately, not all cases fall in this class, and some of the important ones are fall outside, like the travelling salesman problem mentioned above.\\

A given task is said to be in the class NP, if the solution can be found in polynomial time by non-deterministic Turing machine. A deterministic Turing machine can only perform one action for a given situation according to its set of rules, while a non-deterministic Turing machine can perform more than one action for a given situation and if any of them find the solution, it achieves its goal. In other word, a non-deterministic Turing machine has the potential to explore exponentially many paths in parallel with time and check if any on of them can solve the task. It's clearly that deterministic Turing machine is a weak version of non-deterministic one. Therefore class P is also included inside the class NP as a special case. Not like a problem in class P, the polynomial-time algorithm know to be exist, problems in class NP are believed to require super-polynomial time. \\

There is a subset inside class NP called NP-complete, which is considered to be the hardest set among class NP and any NP problem can be reduced into class NP-complete with a polynomial overhead. It is general believed that if one can find an polynomial algorithm to solve an NP-complete problem, all problems in class NP can also be solved by this polynomial algorithm.  The task fall inside either class NP or class NP-complete are considered to be hard, because non-deterministic Turing machine is not yet possible to be simulated by a deterministic Turing machine without an exponential growth of execution time. \\ 

Indeed there are algorithms can solve some easy optimisation problems in polynomial time. For harder cases like class NP-complete, although one cannot find the exact solution in a polynomial time, there are still some specialised algorithm that can approximate the solution in an polynomial time. The downside is that these algorithm are very problem specific, which means a success in one NP-complete problem does not ensure the success when attacking other NP problems by using the same algorithm. \\

\subsection{Boolean Satisfiability Problem}

The boolean satisfiability problem, abbreviated as the SAT problem, is a task of checking whether a given set of boolean formula can be satisfied. To be more specific, the goal here is to find a configuration of true or false for all variables in a given Boolean formula and it leads the final evaluation of the formula to true. The formula is called satisfiable when this is the case. On the other hand, the formula is not satisfiable, if the evaluation is false for all possible configuration.  \\

The k-SAT problem with k>2 has been proven to be in class NP-complete, which implies that no algorithm can efficiently solve SAT problems in polynomial time. The parameter k defines the upper limit of the number of variables in one clause. An example is 

\begin{equation*}
 (x_1\lor x_2\lor x_3)\land (x_4\lor x_5\lor \neg x_6),
\end{equation*}

where $\land$,$\lor$, and $\neg$ state for logical and, logical or, and logical not respectively. This is a Boolean formula in 3-SAT form, in which has two clauses and each clause consist of at most 3 variables. This formula is satisfiable because the final evaluation is true while one of the variable is true among $x_1, x_2, x_3$ in the first clause ,and one of the variable is true among $x_4, x_5$ or $x_6$ is false in the second clause. \\

In this work, 2-SAT problem is the target task to understand. Similarly, the definition of a 2-SAT problem is that one clause can contain at most two variables. In contrast to those more general ones which are known to be NP-complete, 2-SAT problem can be solved in polynomial time. A detail should be mentioned is that the 2-SAT problems studied in this work all has only one unique configuration which leads the evaluation to be true. In other words, there is no degenerate ground states for the problem. \\
 
\subsection{The Mapping of Hamiltonian}
\label{The Mapping of Hamiltonian}

A 2-SAT problem can only be solved when its Boolean formula is mapped in to an Ising Hamiltonian. In Ising model, an spin can take either 1 or -1 as its value, so it is straightforward to correspond spin value 1 for logical true and spin value 0 for logical false. \\

The following simple example can help demonstrate the mapping of Hamiltonian. 

\begin{equation*}
(x_1\lor x_2)\land (x_3\lor \neg x_4)
\end{equation*}

The whole statement is true if in the first clause, either $x_1$ or $x_2$ is true and in the second clause, $x_3$ is true or $x_4$ is false. The mapping is as follow:

\begin{table}[h!]



\begin{center}
	\begin{tabular}{|c|c|c|c|c|}
		
		\multicolumn{5}{c}{2-SAT Variables}\\
		\hline
		  & T & T & T & F \\
		\hline
		\hline
		$x_1$ & 1 & 1 & 0 & 0 \\
		\hline
		$x_2$ & 1 & 0 & 1 & 0 \\
		\hline
	\end{tabular}
	\quad
	$\Rightarrow$
	\quad
	\begin{tabular}{|c|c|c|c|c|}
		\multicolumn{5}{c}{Ising variables}\\
		\hline
		 & T & T & T & F \\
		\hline
		\hline
		$\sigma_1$ & 1 & 1 & -1 & -1 \\
		\hline
		$\sigma_2$ & 1 & -1 & 1 & -1 \\
		\hline
		$m=\sigma_1+\sigma_2$ & 2 & 0 & 0 & -2 \\
		\hline
	\end{tabular}
\end{center}

\begin{center}
	\begin{tabular}{|c|c|c|c|c|}

		\hline
		& T & T & T & F \\
		\hline
		\hline
		$x_3$ & 1 & 1 & 0 & 0 \\
		\hline
		$x_4$ & 0 & 1 & 0 & 1 \\
		\hline
		
	\end{tabular}
		\quad
		$\Rightarrow$
		\quad
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			& T & T & T & F \\
			\hline
			\hline
			$\sigma_3$ & 1 & 1 & -1 & -1 \\
			\hline
			$\sigma_4$ & -1 & 1 & -1 & 1 \\
			\hline
			$m=\sigma_3-\sigma_2$ & 2 & 0 & 0 & -2 \\
			\hline
		\end{tabular} 

\end{center}
\caption{A way to map the 2-SAT clauses to the Ising variables.}
\end{table} 

In order to encode the solution of the 2-SAT problem into the ground state of the Ising Hamiltonian, an Ising Hamiltonian can be built up with a magnetisation $m$. The Hamiltonian with magnetisation $m$ is given by 

\begin{equation}
\begin{split}
H & = m \cdot (m-2)\\
  & = \sigma_i^2 + \sigma_j^2 + 2\sigma_i \sigma_j -2\sigma_i -2\sigma_j\\
  & = 2\sigma_i \sigma_j -2\sigma_i -2\sigma_j + const.\\
\end{split}
\end{equation}

After comparing with the Hamiltonian mentioned in previous section, one can correspond $h_i^z$, $h_j^z$, and $J_{ij}$ to 2, 2, and -2 respectively. Then one just repeats this procedure for all clauses. After this mapping is complete, the original 2-SAT problem can be solved with quantum annealing technique, because the ground state of the Ising Hamiltonian can be transformed back to the solution of the 2-SAT problem. \\  







\section {Simulation Algorithm}
\subsection{Algorithm for Ideal Case}
So here i am going to try out two algorithm. First is full diagonalization, which i use Lapack to solve the eigensystem. Product formula break the evolution into small operation and make the computation of large system possible.
\subsubsection{Full Diagonalization}
Use Lapack to diagonalize the H for $\Psi_{t} = e^{iH\tau} \Psi_{t-\tau}$. 

Check Reference \cite{DeRaedt2004} B.Full Diagonalization Approach

\subsubsection{Suzuki-Trotter Product Formula}
Check Reference \cite{DeRaedt2004}  E. Suzuki-Trotter Product-Formula Algorithms

Break the H to small operation that operate on the state. According to $J^x , J^y, and Jz; h^x, h^y, and h^z$, we need to find the pair or quad pair for the $\Psi$

$\circ \circ \circ ,0, \circ$

$\circ \circ \circ ,1, \circ$

$\circ ,0, \circ ,0, \circ$

$\circ ,0, \circ ,1, \circ$

$\circ ,1, \circ ,0, \circ$

$\circ ,1, \circ ,1, \circ$

\subsection{Algorithm for system with Temperature Effect}
Here since we have in total 16 spins, of course we cannot use product formula algorithm. But we because have temperature term now, which means we may run over several states, therefore the product formula algorithm is not enough for use now. Therefore, we use random sampling method.
\subsubsection{Boltzmann Distribution/ Assemble Average}
???	By adding environment, the temperature will affect how many state should we calculate
We still use product formula. and we use assemble average to calculate each initial state exactly.
\subsubsection{Random wave function}
Reference check! II Theory part.
\cite{Hams2000} 





\section{Quantum Annealer Simulation: Ideal Case}
	There is no ideal system. Environment will always affect the subsystem. However, I start from a simple case, that is a subsystem without environment effect. 
\subsection{??Simulation Set up}
	8 spin without environment spin. With linear time scheme. 

\subsection{Result}
\subsection{the evolution of the spin, energy, and success probability during the annealing}
	A general picture on the annealing behaviour. The expectation value of spin should start from x direction and end up in z direction. During the process y may only have some fluctuation. For the energy of subsystem we expect it to first increase and then decrease to a lower level. We knew the ground state ready, so in the end we expect to see the ground state evolute form 0 to 1, if this is a successful annealing.
	\begin{itemize}
		\item \checkmark Figure here: The system energy vs. lambda
		\item \checkmark Figure here: The spin x vs. lambda
		\item \checkmark Figure here: The spin z vs. lambda
		\item \checkmark Figure here: The success probability vs. lambda
	\end{itemize}
\subsubsection{The Effect of step size tau}
	After having a look at the general properties. Now I try to investigate the size of time step. When the Hamiltonian is time-dependent. The tau should be small enough.  other wise the result would deviate. 
	\begin{itemize}
		\item \checkmark Figure here: compare the result of product formula with the result of full diagonalization: success probability vs. annealing Time with different tau.
	\end{itemize}
\subsubsection{The Effect of Annealing Time}
	Setting up the proper $\tau$. Then I start to simulate the annealing process with different annealing time. The annealing should be long enough to find a ground state. Also I compare the result of full diagonalization and product formula algorithm. 
	\begin{itemize}
		\item Figure here: compare the result of different annealing time of full diagonalization: success probability vs.lambda with different annealing time
		\item \checkmark Figure here: compare the result of different annealing time of full diagonalization: success probability vs.lambda with different annealing time
		\item \checkmark Figure here: compare the result of different annealing time of full diagonalization: energy vs.lambda with different annealing time
		\item \checkmark Figure here: compare the result of different annealing time of full diagonalization: energy vs.lambda with different annealing time
	\end{itemize}
\subsubsection{The Effect of Minimum Gap}
	According to Landau-Zener theorem, the successful probability depend on the gap in between the ground state and the first excited state.
	\begin{itemize}
		\item \checkmark Figure here: energy spectrum: the energy for all states vs. lambda
		\item \checkmark Figure here: a close view of the result above: the energy for lowest 20~30 states vs. lambda
		\item \checkmark Figure here: compare: the success probability under the annealing time that maximise the minimum gap difference vs. minimum gap value 
	\end{itemize}
	
\section{Quantum Annealer Simulation with Temperature Effect}
	After the case without environment, now we move on to the one with environment.
\subsection{??Simulation Set up}
	Here the system consist of a 8-spins subsystem and 8-spins environment. The interaction depend on the coupling factor. When factor is 0, the subsystem cannot be affected by the environment at all. On the other, if the factor is 1, the spin of environment may fully interact with subsystem just as one of the spin inside.

\subsection{Result}
\subsubsection{The Effect of Temperature}
	\begin{itemize}
		\item Figure here: display plots with different coupling factor: success probability of a coupling factor with different temperature vs. annealing Time
	\end{itemize}
\subsubsection{The Process toward Quasi-static}
	See Fig 3 of this reference	\cite{Amin2015} 
	
	In the beginning of the annealing. The probability of finding the ground state may still increase, because the environment haven't yet to affect the subsystem. Then when the environment start interacting with subsystem. After it equilibrium with the subsystem. It will continuous to anneal and the probability will increase. 
	\begin{itemize}
		\item \checkmark Figure here: display plots with different temperature: success probability with different coupling factor vs. annealing time
		
		\item \checkmark Figure here: repeat above plots with Random wave function
	\end{itemize}
	
	
\subsubsection{The Effect of Annealing Time}
	This subsection may be removed 
\subsubsection{The Effect of Minimum Gap}
	So the scatter effect come from the spin numbering. When the coupling factor become larger and larger. The sccatering effect become more clear. On the other hand, Temperature is not the critical reason to this phenomenon. But the temperature will also enlarge the scatter. The temperature has an influence on how many environment state are part of the evolution. If the temperature is low the revolution only in the ground state. When temperatrue is high, almost all environment state is part of the evolution. the state is average out by the environment states. So the scatter of the problem hamiltonian is not clear. Also since we are in an effective temperature unit. delta gap/Temperature. Therefore, when temperature is larger than gap, they are in excited state. so the annealing is not clear and cant find the ground state. vice versa. when the temperature is smaller than 1. we can see the annealing effect and probability to find the ground state. 
	\begin{itemize}
		\item \checkmark Figure here: compare: the success probability under the annealing time that maximise the minimum gap difference vs. minimum gap value.
	\end{itemize}
\section{??D-wave Practice}
	\cite{Johnson2011}
	D-wave use of super conducting qubit
	
\section{??Parallelization}
	\definecolor{light-gray}{gray}{0.4}
	\textcolor{light-gray}{Shoul I put the result of openMP parallerization?}
	It is obvious that i cant put the parallization in between the different time step, because they depend on each other. So i put openmp in side each step for the state. also because the calculation may cause race condition, i have to put it in the second loop instead of the most outside one. this may decrease the optimisation of the running time. However, i think this is the moderate way to get a balance of not getting code too complicate and too slow running time.
	
	! \textcolor{red}{The runtime difference for a single run with core 1,2,4,8,16,32,64,128.}

	
\section{Applicatoin on Machine Learning / Simulation}
	
	\cite{Adachi2015}
	\cite{Benedetti2016}
	\cite{Boyda2017}
	\cite{OMalley2017}
	\cite{Potok2017}
	
	
	Application
	 
	-tree recognition
	
	-hand writing
	
	-face detection
	


\section{Conclusion}
\section{miscellaneous}




Please specify your name, matriculation number, name of advisor and the title of your report in \linebreak
\verb+titlepage.tex+.
The title page will not count for the 20 pages.

Using bibtex you can cite in an organized way and without much work.
Just enter the information about a paper or an article you want to cite in the \verb+seminar_report.bib+ file and use \verb+\cite+ to cite them. For example \cite{Author08CVPR},\cite{Author04IJCV}.
Don't forget to compile the bib file and Latex will add all the cited references at the end.
Cite all the literature you use and state where figures are from!

I am a section. Latex will give me a number \emph{automatically} and put me into the table of contents.
Using \verb+\label+ and \verb+\ref+ you can use Latex to write that this is Section \ref{section}.



\subsection{a subsection}
I am a subsection.

\begin{itemize}
	\item I am an item.
	\item [-] I am another item.
\end{itemize}

\subsubsection{a small subsection}
I am a subsubsection, an even smaller subsection.

\begin{tabular}{|l|c|}
\hline
I am a tabular & with two columns. \\
\hline
The left column is aligned left & and the right columns is centered. \\
\hline
\end{tabular}


\begin{figure}[h]
\centering
\includegraphics[height=100pt]{doge.jpeg}
\caption{Insert caption here. Image from \cite{lenna}. }
\label{example_figure}
\end{figure}
Figure \ref{example_figure} also gets a number automatically and will be placed where Latex thinks it looks good. You can specify a preference with h(ere), t(op), b(ottom), p(age).


%\begin{figure}
%%	\begin{center}
%		\resizebox{!}{!}{\input{pvsgap}}
%%	\end{center}
%\end{figure}

Latex is also really good at printing equations: $E=mc^2$

\begin{equation}
A = \sum_{i=1}^N A_1 \cdot A_2
\end{equation}

\subsubsection{Possible Material}
Result on spin and Energy env,sys,se

success probability of ground state

spin system

energy spectrum

evolution of spin and energy

Runtime comparison

Parallel possibility

-Introduction

-Annealing Theorem

-Full-diagonalization

-suzuki-trotter product formula

-size of tau

-The effect of annealing Time w/ w/o Heat bath

-The effect of minimum gap w/ w/o Heat bath

-Landau-Zener Theorem

-2-SAT problem 

-Random wave function  

-The effect of heat bath(Coherent - Transverse - quasiequilibrium) at different temperature

D-wave practice

-Hamiltonian Mapping

-Annealing Time scheme

-Time-Dependent Schrï¿½dinger Equation

-Boltzmann distribution + trace of the observable


% +++++++++++++++++++++++++

% =========================================================================
\bibliographystyle{alpha}
\bibliography{master_report}

% =========================================================================

\end{document}
